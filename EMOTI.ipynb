{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataload import dataload\n",
    "\n",
    "from module import transformer,video_model,invres\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt\n",
    "from torchvision import  utils\n",
    "import os\n",
    "from constant import EMOTIPATH\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Batchfy\n",
    "#Counts number of correct label\n",
    "def num_correct(prediction,labels):\n",
    "    correct=0\n",
    "    for i,(pred_label,label) in enumerate(zip(prediction,labels)):\n",
    "        if (pred_label.item()==label.item()):\n",
    "            correct +=1\n",
    "    return correct\n",
    "\n",
    "Train_label=os.path.join(EMOTIPATH,\"Train_labels.txt\")\n",
    "Train_video=os.path.join(EMOTIPATH,\"Train\")\n",
    "Val_labels=os.path.join(EMOTIPATH,\"Val_labels.txt\")\n",
    "Val_video=os.path.join(EMOTIPATH,\"Val\")\n",
    "\n",
    "\n",
    "train_data=dataload.Video_Frame_Data(Train_label,base_path_v=Train_video,strict_num=26)\n",
    "valid_data=dataload.Video_Frame_Data(Val_labels,base_path_v=Val_video,strict_num=26)\n",
    "\n",
    "train_data=dataload.Video_Embedding_Data(\"train.csv\",Train_label)\n",
    "valid_data=dataload.Video_Embedding_Data(\"valid.csv\",Val_labels)\n",
    "            \n",
    "train_dataloader = DataLoader(train_data, batch_size=32\n",
    "                       , num_workers=0,shuffle=True)\n",
    "#valid_data=dataload.Video_Frame_Data(Val_labels,base_path_v=Val_video,strict_num=26)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=32\n",
    "                       , num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2661"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 1000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet is frozen\n",
      "fc2 is unfrozen\n",
      "fc3 is unfrozen\n",
      "posencoding is unfrozen\n",
      "transformer is unfrozen\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "model=video_model.Video_Feature(joint=False,grayscale=False,classfication=True,frame=24,skip_process=True)\n",
    "for name, child in model.named_children():\n",
    "   if not name in ['densenet']:\n",
    "       print(name + ' is unfrozen')\n",
    "       for param in child.parameters():\n",
    "           param.requires_grad = True\n",
    "   else:\n",
    "       print(name + ' is frozen')\n",
    "       for param in child.parameters():\n",
    "           param.requires_grad = False\n",
    "#model=model.to(device)  \n",
    "model=model.double().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0002, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(train_data[60][0].unsqueeze(0).to(device))\n",
    "#loss=criterion(output,(train_data[60][1].unsqueeze(0).to(device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4504, 0.3377, 0.2118]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0.00044083595275878906\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    f = open(\"record.txt\",'a')\n",
    "    start = time.time()\n",
    "    #Triaining\n",
    "    train_loss=[]\n",
    "    valid_accuracy=[]\n",
    "    num_epochs=50\n",
    "\n",
    "    model.train()\n",
    "    for epochs in range(0,num_epochs):\n",
    "        first=True\n",
    "        model.train()\n",
    "        correct=0\n",
    "        total_samples=0\n",
    "        avg_tloss=0\n",
    "        print(\"Training Epoch: \", epochs+1,\"\\n\")\n",
    "        for i_batch, (sample_batched,label) in enumerate(train_dataloader):\n",
    "\n",
    "            batch_size=sample_batched.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            sample_batched=sample_batched.to(device)\n",
    "            output=model(sample_batched)\n",
    "            loss=criterion(output,label.to(device))\n",
    "            #loss=loss_func(output,label.float().to(device))\n",
    "            loss.backward()\n",
    "            predicted = torch.max(output, 1)\n",
    "            prediction=predicted.indices.detach().cpu()\n",
    "            correct +=num_correct(prediction,label)\n",
    "            total_samples+=batch_size\n",
    "            accuracy=correct/(total_samples)\n",
    "            optimizer.step()\n",
    "            true_label=label.detach().cpu()\n",
    "            avg_tloss+=loss.item()\n",
    "            if first:\n",
    "                first=False\n",
    "                conf_mat=confusion_matrix( true_label,prediction,labels=[0,1,2])\n",
    "            else:\n",
    "                conf_mat+=confusion_matrix(true_label,prediction,labels=[0,1,2])\n",
    "            if i_batch%20==0:\n",
    "               # print(label)\n",
    "                print(\"Batch: \",i_batch+1,\"/\",len(train_dataloader))\n",
    "                print(\"Batch Recognition loss: \", loss.item())\n",
    "\n",
    "        print(conf_mat)\n",
    "        avg_tloss=avg_tloss/len(train_dataloader)\n",
    "        avg_taccuracy=correct/total_samples\n",
    "        print(\"Average_Loss: \",avg_tloss)\n",
    "        print(\"Average_Accuracy: \",avg_taccuracy)\n",
    "\n",
    "        torch.save(model,\"pre_embedded_model.h\")\n",
    "        print(\"Validation\\n\")\n",
    "\n",
    "        model.eval()   \n",
    "        correct=0\n",
    "        total_samples=0\n",
    "        avg_vloss=0\n",
    "        first=True\n",
    "        for i_batch, (sample_batched,label) in enumerate(valid_dataloader):\n",
    "            batch_size=sample_batched.size(0)\n",
    "            sample_batched=sample_batched.to(device)\n",
    "            output=model(sample_batched)\n",
    "            loss=criterion(output,label.to(device))\n",
    "          #  loss=loss_func(output,label.float().to(device))\n",
    "            avg_vloss+=loss.item()\n",
    "            predicted = torch.max(output, 1)\n",
    "            prediction=predicted.indices.detach().cpu()\n",
    "            correct +=num_correct(prediction,label)\n",
    "            total_samples+=batch_size\n",
    "\n",
    "            true_label=label.detach().cpu()\n",
    "            if first:\n",
    "                first=False\n",
    "                conf_mat=confusion_matrix( true_label,prediction,labels=[0,1,2])\n",
    "            else:\n",
    "                conf_mat+=confusion_matrix(true_label,prediction,labels=[0,1,2])\n",
    "        print(conf_mat)\n",
    "        avg_vloss=avg_vloss/len(valid_dataloader)\n",
    "        print(avg_vloss)\n",
    "        avg_vaccuracy=correct/(total_samples)\n",
    "        print(\"Accuracy: \", avg_vaccuracy)\n",
    "\n",
    "        data = \" %f,%f,%f,%f \\n\" % (avg_tloss,avg_taccuracy,avg_vloss,avg_vaccuracy)\n",
    "        f.write(data)\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch:  1 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  1.1033068308692027\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.9736362753942537\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  1.06371463956777\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  1.0322192310128195\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  1.032958129988899\n",
      "[[211 344 251]\n",
      " [147 531 245]\n",
      " [124 217 591]]\n",
      "Average_Loss:  1.020135674673681\n",
      "Average_Accuracy:  0.5009394964299135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Video_Feature. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _Transition. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PositionalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiHeadAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ScaledDotProductAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "\n",
      "[[ 63 220  16]\n",
      " [ 33 237  11]\n",
      " [ 25 127  34]]\n",
      "1.0566617588461964\n",
      "Accuracy:  0.4360313315926893\n",
      "Training Epoch:  2 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  1.10165682205472\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.9455683327626325\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.9841308043607134\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.9564243770641683\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.9453405667828264\n",
      "[[388 235 183]\n",
      " [237 503 183]\n",
      " [128 142 662]]\n",
      "Average_Loss:  0.9465167326457584\n",
      "Average_Accuracy:  0.5836151822623074\n",
      "Validation\n",
      "\n",
      "[[115 135  49]\n",
      " [ 39 209  33]\n",
      " [ 19  87  80]]\n",
      "0.9974400033126803\n",
      "Accuracy:  0.5274151436031331\n",
      "Training Epoch:  3 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8289223225583433\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  1.0051619309518471\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  1.0269501795182123\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7736601793863856\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8570295060813609\n",
      "[[438 214 154]\n",
      " [193 547 183]\n",
      " [106 134 692]]\n",
      "Average_Loss:  0.9102565863439499\n",
      "Average_Accuracy:  0.6302142051860203\n",
      "Validation\n",
      "\n",
      "[[ 93 168  38]\n",
      " [ 32 216  33]\n",
      " [ 33  88  65]]\n",
      "1.0240216117738823\n",
      "Accuracy:  0.48825065274151436\n",
      "Training Epoch:  4 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8178037437412106\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  1.006915314334387\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.935253116505052\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8834840556555141\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8533243640403136\n",
      "[[497 174 135]\n",
      " [198 561 164]\n",
      " [ 89 124 719]]\n",
      "Average_Loss:  0.8788277128209436\n",
      "Average_Accuracy:  0.6677940623825629\n",
      "Validation\n",
      "\n",
      "[[211  64  24]\n",
      " [124 132  25]\n",
      " [ 85  49  52]]\n",
      "1.0070846046162152\n",
      "Accuracy:  0.5156657963446475\n",
      "Training Epoch:  5 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  1.0466829194444407\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7451868084363051\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8872870639841675\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.9312759104631215\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.987532650362045\n",
      "[[541 149 116]\n",
      " [207 557 159]\n",
      " [ 90 123 719]]\n",
      "Average_Loss:  0.8633128644551222\n",
      "Average_Accuracy:  0.68282600526118\n",
      "Validation\n",
      "\n",
      "[[198  61  40]\n",
      " [132 120  29]\n",
      " [ 53  55  78]]\n",
      "1.0076813127577247\n",
      "Accuracy:  0.5169712793733682\n",
      "Training Epoch:  6 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.9376730108356452\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.9222319266061159\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8113176996343925\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7684396273447351\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.9425788560934424\n",
      "[[539 155 112]\n",
      " [197 570 156]\n",
      " [ 82 128 722]]\n",
      "Average_Loss:  0.8553679265207296\n",
      "Average_Accuracy:  0.6880871852686959\n",
      "Validation\n",
      "\n",
      "[[172  62  65]\n",
      " [ 99 132  50]\n",
      " [ 35  64  87]]\n",
      "1.0082452696072444\n",
      "Accuracy:  0.5104438642297651\n",
      "Training Epoch:  7 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.9609629423328285\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.885362777761541\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.961906550771798\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.9339747604482806\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7857267999150547\n",
      "[[535 154 117]\n",
      " [203 572 148]\n",
      " [ 93 112 727]]\n",
      "Average_Loss:  0.8501941495162397\n",
      "Average_Accuracy:  0.6892145809845922\n",
      "Validation\n",
      "\n",
      "[[199  78  22]\n",
      " [109 148  24]\n",
      " [ 77  44  65]]\n",
      "0.9821663072486743\n",
      "Accuracy:  0.5378590078328982\n",
      "Training Epoch:  8 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7917034600035072\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7798047266905467\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8163991856991766\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8820140674572209\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7868390731837528\n",
      "[[559 148  99]\n",
      " [168 604 151]\n",
      " [ 78 115 739]]\n",
      "Average_Loss:  0.8339360106203554\n",
      "Average_Accuracy:  0.7147688838782412\n",
      "Validation\n",
      "\n",
      "[[132  53 114]\n",
      " [ 86 128  67]\n",
      " [ 11  30 145]]\n",
      "1.0070971371155588\n",
      "Accuracy:  0.5287206266318538\n",
      "Training Epoch:  9 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7400128468908492\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.9046598141613545\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8578065144486076\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8460801850689075\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8803051637696974\n",
      "[[537 163 106]\n",
      " [196 593 134]\n",
      " [ 78 123 731]]\n",
      "Average_Loss:  0.8451516200717604\n",
      "Average_Accuracy:  0.6993611424276588\n",
      "Validation\n",
      "\n",
      "[[197  66  36]\n",
      " [106 142  33]\n",
      " [ 51  59  76]]\n",
      "0.973649071881404\n",
      "Accuracy:  0.54177545691906\n",
      "Training Epoch:  10 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8104736060474972\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7452614057109822\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.799357663428426\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8785702628942299\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7664332598753938\n",
      "[[551 152 103]\n",
      " [170 621 132]\n",
      " [ 67 128 737]]\n",
      "Average_Loss:  0.8277627268211175\n",
      "Average_Accuracy:  0.7173994738819992\n",
      "Validation\n",
      "\n",
      "[[125  47 127]\n",
      " [ 95 115  71]\n",
      " [ 18  22 146]]\n",
      "1.0212994127060446\n",
      "Accuracy:  0.5039164490861618\n",
      "Training Epoch:  11 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.9160212167155154\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.8384098405598039\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.859215784311365\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7105574176517647\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7978403348315403\n",
      "[[558 143 105]\n",
      " [137 664 122]\n",
      " [ 47 125 760]]\n",
      "Average_Loss:  0.8078875630187874\n",
      "Average_Accuracy:  0.7448327696354754\n",
      "Validation\n",
      "\n",
      "[[107  68 124]\n",
      " [ 54 147  80]\n",
      " [ 12  24 150]]\n",
      "1.0080863642948372\n",
      "Accuracy:  0.5274151436031331\n",
      "Training Epoch:  12 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7753869623537427\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.8656078563587951\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7503077517146998\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6488512329851359\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7221506980985613\n",
      "[[567 149  90]\n",
      " [134 662 127]\n",
      " [ 54 108 770]]\n",
      "Average_Loss:  0.8021216914832683\n",
      "Average_Accuracy:  0.7512213453588876\n",
      "Validation\n",
      "\n",
      "[[173  62  64]\n",
      " [ 96 138  47]\n",
      " [ 32  64  90]]\n",
      "1.0007873614441476\n",
      "Accuracy:  0.5234986945169713\n",
      "Training Epoch:  13 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6912117682746665\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7339962201231576\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6754073793457955\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8644133387996921\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.9178831997922392\n",
      "[[556 162  88]\n",
      " [127 679 117]\n",
      " [ 51 129 752]]\n",
      "Average_Loss:  0.8014469844153707\n",
      "Average_Accuracy:  0.7467117624953025\n",
      "Validation\n",
      "\n",
      "[[117  97  85]\n",
      " [ 65 155  61]\n",
      " [ 22  26 138]]\n",
      "0.9946352098168859\n",
      "Accuracy:  0.5352480417754569\n",
      "Training Epoch:  14 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.9359958610351021\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.9517945745747547\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7762710665218104\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8964765261804231\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8806250449561243\n",
      "[[567 152  87]\n",
      " [139 657 127]\n",
      " [ 52 113 767]]\n",
      "Average_Loss:  0.7968032822558594\n",
      "Average_Accuracy:  0.7482149567831642\n",
      "Validation\n",
      "\n",
      "[[166  28 105]\n",
      " [122  88  71]\n",
      " [ 22  27 137]]\n",
      "1.018997663338901\n",
      "Accuracy:  0.5104438642297651\n",
      "Training Epoch:  15 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8265476417845723\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7793321344929395\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6917543426488578\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8170621201942546\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.735847355707922\n",
      "[[581 141  84]\n",
      " [115 688 120]\n",
      " [ 42 105 785]]\n",
      "Average_Loss:  0.7791399595957825\n",
      "Average_Accuracy:  0.7718902668169861\n",
      "Validation\n",
      "\n",
      "[[199  23  77]\n",
      " [119  93  69]\n",
      " [ 42  18 126]]\n",
      "0.9913204846281719\n",
      "Accuracy:  0.5456919060052219\n",
      "Training Epoch:  16 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8422244916106786\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6386441556256304\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8457602393100722\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8121702606018523\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8318979565052188\n",
      "[[583 140  83]\n",
      " [133 691  99]\n",
      " [ 45 120 767]]\n",
      "Average_Loss:  0.7809067479949748\n",
      "Average_Accuracy:  0.7670048853814355\n",
      "Validation\n",
      "\n",
      "[[147  65  87]\n",
      " [ 87 122  72]\n",
      " [ 22  61 103]]\n",
      "1.0430975582168058\n",
      "Accuracy:  0.4856396866840731\n",
      "Training Epoch:  17 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7479171900064765\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.8249652404097324\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7483586725035323\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8221373552605443\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7071255299799232\n",
      "[[575 145  86]\n",
      " [119 687 117]\n",
      " [ 33 117 782]]\n",
      "Average_Loss:  0.7812801024454176\n",
      "Average_Accuracy:  0.7681322810973318\n",
      "Validation\n",
      "\n",
      "[[171  81  47]\n",
      " [ 91 149  41]\n",
      " [ 52  52  82]]\n",
      "0.9966220684897928\n",
      "Accuracy:  0.5248041775456919\n",
      "Training Epoch:  18 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7440673995305112\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.844854709147283\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8166589180734375\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7278498260996191\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.859362097453845\n",
      "[[601 132  73]\n",
      " [115 711  97]\n",
      " [ 43 109 780]]\n",
      "Average_Loss:  0.7686006505819518\n",
      "Average_Accuracy:  0.7861706125516723\n",
      "Validation\n",
      "\n",
      "[[122  61 116]\n",
      " [ 85 127  69]\n",
      " [ 17  35 134]]\n",
      "1.030466627238835\n",
      "Accuracy:  0.5\n",
      "Training Epoch:  19 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8027411944568154\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.710696555408829\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.750098597625615\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8156094035270076\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8744826345806789\n",
      "[[606 122  78]\n",
      " [109 710 104]\n",
      " [ 39 112 781]]\n",
      "Average_Loss:  0.7658111424163927\n",
      "Average_Accuracy:  0.7880496054114995\n",
      "Validation\n",
      "\n",
      "[[146  37 116]\n",
      " [107 105  69]\n",
      " [ 23  19 144]]\n",
      "1.020146269697588\n",
      "Accuracy:  0.5156657963446475\n",
      "Training Epoch:  20 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.702045277088653\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7755650110428335\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8200706344088395\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8832900939381434\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6188169650007334\n",
      "[[604 128  74]\n",
      " [118 687 118]\n",
      " [ 41 119 772]]\n",
      "Average_Loss:  0.7721748748010423\n",
      "Average_Accuracy:  0.7752724539646749\n",
      "Validation\n",
      "\n",
      "[[158  25 116]\n",
      " [129  72  80]\n",
      " [ 34   9 143]]\n",
      "1.0423683806578676\n",
      "Accuracy:  0.4869451697127937\n",
      "Training Epoch:  21 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8112883920518181\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7776877012153778\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7859785103595213\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8444007320828519\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7946557857328137\n",
      "[[612 129  65]\n",
      " [107 703 113]\n",
      " [ 42  99 791]]\n",
      "Average_Loss:  0.7580963222739071\n",
      "Average_Accuracy:  0.7914317925591883\n",
      "Validation\n",
      "\n",
      "[[188  41  70]\n",
      " [116 118  47]\n",
      " [ 65  32  89]]\n",
      "1.0071514166134783\n",
      "Accuracy:  0.5156657963446475\n",
      "Training Epoch:  22 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.728163078415189\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7501874285544471\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6891399043684068\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7499059462995838\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8547379313157943\n",
      "[[622 120  64]\n",
      " [116 696 111]\n",
      " [ 31 110 791]]\n",
      "Average_Loss:  0.756313744228288\n",
      "Average_Accuracy:  0.7925591882750845\n",
      "Validation\n",
      "\n",
      "[[162  67  70]\n",
      " [ 85 139  57]\n",
      " [ 35  30 121]]\n",
      "0.9793788899330894\n",
      "Accuracy:  0.5509138381201044\n",
      "Training Epoch:  23 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7065625680547928\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7836042116269827\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7726944401841285\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6396829942737209\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7468291168632211\n",
      "[[638 112  56]\n",
      " [107 714 102]\n",
      " [ 42  99 791]]\n",
      "Average_Loss:  0.745985454469497\n",
      "Average_Accuracy:  0.8053363397219091\n",
      "Validation\n",
      "\n",
      "[[131  44 124]\n",
      " [ 74 109  98]\n",
      " [ 15  27 144]]\n",
      "1.034485383502471\n",
      "Accuracy:  0.5013054830287206\n",
      "Training Epoch:  24 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6891674840202419\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6799228058115684\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7233378775106979\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6806436368714566\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.851527492205822\n",
      "[[625 120  61]\n",
      " [ 99 717 107]\n",
      " [ 43  97 792]]\n",
      "Average_Loss:  0.7457480384805173\n",
      "Average_Accuracy:  0.8019541525742202\n",
      "Validation\n",
      "\n",
      "[[198  37  64]\n",
      " [114 105  62]\n",
      " [ 41  37 108]]\n",
      "0.9971026515921827\n",
      "Accuracy:  0.5365535248041775\n",
      "Training Epoch:  25 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8088407998131326\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7953844513213846\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8948314926467416\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6684733331237476\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7466083304931664\n",
      "[[630 114  62]\n",
      " [104 708 111]\n",
      " [ 41 107 784]]\n",
      "Average_Loss:  0.754041753370833\n",
      "Average_Accuracy:  0.7974445697106352\n",
      "Validation\n",
      "\n",
      "[[160  46  93]\n",
      " [ 95 101  85]\n",
      " [ 29  27 130]]\n",
      "1.022027363392411\n",
      "Accuracy:  0.5104438642297651\n",
      "Training Epoch:  26 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7816472740652268\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7743352468791243\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6335709055480656\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7742043248422049\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6366664151974897\n",
      "[[628 112  66]\n",
      " [ 88 733 102]\n",
      " [ 47  93 792]]\n",
      "Average_Loss:  0.7398432185376583\n",
      "Average_Accuracy:  0.8090943254415633\n",
      "Validation\n",
      "\n",
      "[[167  52  80]\n",
      " [ 85 137  59]\n",
      " [ 36  41 109]]\n",
      "0.989232303161831\n",
      "Accuracy:  0.5391644908616188\n",
      "Training Epoch:  27 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7377495300742795\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7034899006372353\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7320819783950466\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7094234321815183\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7402943578956125\n",
      "[[646 100  60]\n",
      " [ 89 735  99]\n",
      " [ 33  96 803]]\n",
      "Average_Loss:  0.731858229764134\n",
      "Average_Accuracy:  0.8207440811724915\n",
      "Validation\n",
      "\n",
      "[[162  66  71]\n",
      " [ 81 141  59]\n",
      " [ 48  35 103]]\n",
      "1.0053868793547676\n",
      "Accuracy:  0.5300261096605744\n",
      "Training Epoch:  28 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6901814095686756\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6849801877164827\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7146749171427328\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.791112552705626\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7873078232133195\n",
      "[[637 105  64]\n",
      " [ 69 753 101]\n",
      " [ 34 101 797]]\n",
      "Average_Loss:  0.7281102698422133\n",
      "Average_Accuracy:  0.8218714768883878\n",
      "Validation\n",
      "\n",
      "[[182  27  90]\n",
      " [133  83  65]\n",
      " [ 41  18 127]]\n",
      "1.0325867017359756\n",
      "Accuracy:  0.5117493472584856\n",
      "Training Epoch:  29 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7841229258200061\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7436180771295794\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6937908146853169\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.789236535916632\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8658457681293402\n",
      "[[633 107  66]\n",
      " [ 91 740  92]\n",
      " [ 41  95 796]]\n",
      "Average_Loss:  0.73607045150682\n",
      "Average_Accuracy:  0.8151071025930101\n",
      "Validation\n",
      "\n",
      "[[117  36 146]\n",
      " [ 71 114  96]\n",
      " [ 12  17 157]]\n",
      "1.037430328465188\n",
      "Accuracy:  0.5065274151436031\n",
      "Training Epoch:  30 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7415391830887534\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.680621002499365\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7590702884825292\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6791837309639001\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7178098650534468\n",
      "[[643 102  61]\n",
      " [ 89 743  91]\n",
      " [ 34  91 807]]\n",
      "Average_Loss:  0.7252235847678928\n",
      "Average_Accuracy:  0.8241262683201804\n",
      "Validation\n",
      "\n",
      "[[174  32  93]\n",
      " [117  98  66]\n",
      " [ 37  32 117]]\n",
      "1.0295304681043393\n",
      "Accuracy:  0.5078328981723238\n",
      "Training Epoch:  31 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8455997638189552\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7385004426388584\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7360155689207584\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7873843509753854\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7891350370441261\n",
      "[[635 109  62]\n",
      " [ 97 722 104]\n",
      " [ 41  89 802]]\n",
      "Average_Loss:  0.7373298611340877\n",
      "Average_Accuracy:  0.8113491168733559\n",
      "Validation\n",
      "\n",
      "[[205  18  76]\n",
      " [128  86  67]\n",
      " [ 73   8 105]]\n",
      "1.0198676024666284\n",
      "Accuracy:  0.5169712793733682\n",
      "Training Epoch:  32 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6662808542818445\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.804563795189337\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7075221361227334\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7625398707704922\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7207456734991812\n",
      "[[614 129  63]\n",
      " [109 721  93]\n",
      " [ 34  89 809]]\n",
      "Average_Loss:  0.7433640069015438\n",
      "Average_Accuracy:  0.8057121382938744\n",
      "Validation\n",
      "\n",
      "[[129  97  73]\n",
      " [ 64 162  55]\n",
      " [ 27  57 102]]\n",
      "1.0240567508535425\n",
      "Accuracy:  0.5130548302872062\n",
      "Training Epoch:  33 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6773759068212094\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6990624388454127\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8507088003415261\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7977369689336327\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7205891377051982\n",
      "[[630 116  60]\n",
      " [ 77 753  93]\n",
      " [ 25  88 819]]\n",
      "Average_Loss:  0.7270695077763634\n",
      "Average_Accuracy:  0.8275084554678692\n",
      "Validation\n",
      "\n",
      "[[201  39  59]\n",
      " [100 123  58]\n",
      " [ 50  43  93]]\n",
      "0.9983262802529814\n",
      "Accuracy:  0.5443864229765013\n",
      "Training Epoch:  34 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.791080134087434\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7733064164082629\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.712960981607885\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.8335737082316687\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.712118247558175\n",
      "[[646 100  60]\n",
      " [ 85 750  88]\n",
      " [ 26  89 817]]\n",
      "Average_Loss:  0.7176350539255015\n",
      "Average_Accuracy:  0.8316422397594889\n",
      "Validation\n",
      "\n",
      "[[133 109  57]\n",
      " [ 58 171  52]\n",
      " [ 31  63  92]]\n",
      "1.022427709327046\n",
      "Accuracy:  0.5169712793733682\n",
      "Training Epoch:  35 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7739317271847249\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6743663811479194\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7898651172269391\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6630575925416724\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.8024501828746974\n",
      "[[634 106  66]\n",
      " [104 719 100]\n",
      " [ 30  86 816]]\n",
      "Average_Loss:  0.7339504176126148\n",
      "Average_Accuracy:  0.8151071025930101\n",
      "Validation\n",
      "\n",
      "[[156  66  77]\n",
      " [ 93 125  63]\n",
      " [ 33  22 131]]\n",
      "0.9941334288998046\n",
      "Accuracy:  0.5378590078328982\n",
      "Training Epoch:  36 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6033273304846841\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.8708181945551954\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6460288052015347\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7214111858550042\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7202220107578237\n",
      "[[646  99  61]\n",
      " [ 85 733 105]\n",
      " [ 27  80 825]]\n",
      "Average_Loss:  0.7205103152113113\n",
      "Average_Accuracy:  0.8282600526118\n",
      "Validation\n",
      "\n",
      "[[208  30  61]\n",
      " [129  98  54]\n",
      " [ 53  39  94]]\n",
      "1.0175282093761655\n",
      "Accuracy:  0.5221932114882507\n",
      "Training Epoch:  37 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7485602045960273\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6651622739838036\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6832751976855276\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6833916044530676\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7295984464999345\n",
      "[[655 100  51]\n",
      " [ 83 755  85]\n",
      " [ 26  87 819]]\n",
      "Average_Loss:  0.7120024539055129\n",
      "Average_Accuracy:  0.8376550169109357\n",
      "Validation\n",
      "\n",
      "[[210  46  43]\n",
      " [126 123  32]\n",
      " [ 87  40  59]]\n",
      "1.0221546938881854\n",
      "Accuracy:  0.5117493472584856\n",
      "Training Epoch:  38 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7773065333548871\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.8068668709068179\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8665983364692735\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.741627908608752\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6434769156952728\n",
      "[[639 113  54]\n",
      " [119 721  83]\n",
      " [ 55 112 765]]\n",
      "Average_Loss:  0.7478446635998474\n",
      "Average_Accuracy:  0.7985719654265314\n",
      "Validation\n",
      "\n",
      "[[160  66  73]\n",
      " [ 82 145  54]\n",
      " [ 31  30 125]]\n",
      "0.9818324919267357\n",
      "Accuracy:  0.5613577023498695\n",
      "Training Epoch:  39 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7288113747647862\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7593272613896307\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6659924075500709\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7874671438377973\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6404645657728404\n",
      "[[640 106  60]\n",
      " [ 82 762  79]\n",
      " [ 36  89 807]]\n",
      "Average_Loss:  0.7201330811183212\n",
      "Average_Accuracy:  0.8301390454716272\n",
      "Validation\n",
      "\n",
      "[[212  43  44]\n",
      " [118 125  38]\n",
      " [ 83  26  77]]\n",
      "1.0009192921305334\n",
      "Accuracy:  0.5404699738903395\n",
      "Training Epoch:  40 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7042816904304826\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6479468708048471\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7540754673089345\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6854661693705166\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7688947825545316\n",
      "[[653 100  53]\n",
      " [119 711  93]\n",
      " [ 38  85 809]]\n",
      "Average_Loss:  0.7322389314393728\n",
      "Average_Accuracy:  0.8166102968808718\n",
      "Validation\n",
      "\n",
      "[[215  42  42]\n",
      " [123 120  38]\n",
      " [ 79  35  72]]\n",
      "1.0055036411053833\n",
      "Accuracy:  0.5313315926892951\n",
      "Training Epoch:  41 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.768034365233911\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6752620168044478\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7302299578684498\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6939589384794409\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.744935122038214\n",
      "[[663  93  50]\n",
      " [ 90 751  82]\n",
      " [ 46  86 800]]\n",
      "Average_Loss:  0.7194675799027912\n",
      "Average_Accuracy:  0.8320180383314544\n",
      "Validation\n",
      "\n",
      "[[173  49  77]\n",
      " [113 109  59]\n",
      " [ 46  30 110]]\n",
      "1.022615765283215\n",
      "Accuracy:  0.5117493472584856\n",
      "Training Epoch:  42 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6578400103813529\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6980526129291086\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7230981726353924\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7988511323148012\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7482274443420505\n",
      "[[662  86  58]\n",
      " [ 95 740  88]\n",
      " [ 32  88 812]]\n",
      "Average_Loss:  0.7163211060136815\n",
      "Average_Accuracy:  0.8320180383314544\n",
      "Validation\n",
      "\n",
      "[[190  66  43]\n",
      " [145 108  28]\n",
      " [ 53  64  69]]\n",
      "1.0614027603178025\n",
      "Accuracy:  0.47911227154047\n",
      "Training Epoch:  43 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.8036270627338232\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7131530787834968\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8517376860638214\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.753648253017462\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7404798934021756\n",
      "[[646  96  64]\n",
      " [ 99 733  91]\n",
      " [ 51 111 770]]\n",
      "Average_Loss:  0.7374838009626806\n",
      "Average_Accuracy:  0.8075911311537016\n",
      "Validation\n",
      "\n",
      "[[200  16  83]\n",
      " [123  87  71]\n",
      " [ 47  13 126]]\n",
      "1.0043051473895248\n",
      "Accuracy:  0.5391644908616188\n",
      "Training Epoch:  44 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6498426766942147\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7417891536135757\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.5567704804894232\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.716819456893652\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7400833785214342\n",
      "[[683  78  45]\n",
      " [ 79 756  88]\n",
      " [ 28  83 821]]\n",
      "Average_Loss:  0.7032027697435955\n",
      "Average_Accuracy:  0.849304772641864\n",
      "Validation\n",
      "\n",
      "[[208  15  76]\n",
      " [155  64  62]\n",
      " [ 44  24 118]]\n",
      "1.0323790700956141\n",
      "Accuracy:  0.5091383812010444\n",
      "Training Epoch:  45 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6386333324955413\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6904284046567549\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7580217147430385\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6474363971490065\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6819846377764648\n",
      "[[674  82  50]\n",
      " [ 96 753  74]\n",
      " [ 36  78 818]]\n",
      "Average_Loss:  0.7060337897275907\n",
      "Average_Accuracy:  0.8436677940623826\n",
      "Validation\n",
      "\n",
      "[[175  41  83]\n",
      " [104 104  73]\n",
      " [ 41  29 116]]\n",
      "1.0292483867666613\n",
      "Accuracy:  0.5156657963446475\n",
      "Training Epoch:  46 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6164462385295181\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6034632099163111\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7875270131899742\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7120331704078501\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6150640466080269\n",
      "[[666  95  45]\n",
      " [ 79 769  75]\n",
      " [ 26  79 827]]\n",
      "Average_Loss:  0.6986871977272076\n",
      "Average_Accuracy:  0.8500563697857948\n",
      "Validation\n",
      "\n",
      "[[175  52  72]\n",
      " [101 123  57]\n",
      " [ 55  36  95]]\n",
      "1.026438459263835\n",
      "Accuracy:  0.5130548302872062\n",
      "Training Epoch:  47 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.6624606498134631\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.7186469572039992\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.732381628461964\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6767315370824659\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.615032708136502\n",
      "[[668  93  45]\n",
      " [ 73 767  83]\n",
      " [ 23  73 836]]\n",
      "Average_Loss:  0.6957583071621081\n",
      "Average_Accuracy:  0.8534385569334837\n",
      "Validation\n",
      "\n",
      "[[180  69  50]\n",
      " [112 118  51]\n",
      " [ 52  37  97]]\n",
      "1.0206834064794044\n",
      "Accuracy:  0.5156657963446475\n",
      "Training Epoch:  48 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7186013942955375\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6522852737004388\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.6454649055161471\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6873551283755281\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6470106740194213\n",
      "[[662  92  52]\n",
      " [ 73 767  83]\n",
      " [ 26  85 821]]\n",
      "Average_Loss:  0.7035059967587808\n",
      "Average_Accuracy:  0.8455467869222097\n",
      "Validation\n",
      "\n",
      "[[172  47  80]\n",
      " [120  99  62]\n",
      " [ 31  27 128]]\n",
      "1.019900001711468\n",
      "Accuracy:  0.52088772845953\n",
      "Training Epoch:  49 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.7373052216858974\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.5868242901325395\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.7302799143699871\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.7079006136733841\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.6519729471623159\n",
      "[[669  85  52]\n",
      " [ 74 761  88]\n",
      " [ 23  82 827]]\n",
      "Average_Loss:  0.700306241936336\n",
      "Average_Accuracy:  0.8481773769259677\n",
      "Validation\n",
      "\n",
      "[[184  48  67]\n",
      " [117 105  59]\n",
      " [ 49  27 110]]\n",
      "1.0176694246079927\n",
      "Accuracy:  0.52088772845953\n",
      "Training Epoch:  50 \n",
      "\n",
      "Batch:  1 / 84\n",
      "Batch Recognition loss:  0.643681638510769\n",
      "Batch:  21 / 84\n",
      "Batch Recognition loss:  0.6754552542157877\n",
      "Batch:  41 / 84\n",
      "Batch Recognition loss:  0.8041090458779625\n",
      "Batch:  61 / 84\n",
      "Batch Recognition loss:  0.6149970609968238\n",
      "Batch:  81 / 84\n",
      "Batch Recognition loss:  0.7395133602344052\n",
      "[[683  82  41]\n",
      " [ 78 769  76]\n",
      " [ 35  75 822]]\n",
      "Average_Loss:  0.6980680027502141\n",
      "Average_Accuracy:  0.85456595264938\n",
      "Validation\n",
      "\n",
      "[[180  57  62]\n",
      " [128 105  48]\n",
      " [ 70  29  87]]\n",
      "1.047979127395439\n",
      "Accuracy:  0.4856396866840731\n"
     ]
    }
   ],
   "source": [
    "train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.eval()   \n",
    "    correct=0\n",
    "    total_samples=0\n",
    "    avg_vloss=0\n",
    "    first=True\n",
    "    for i_batch, (sample_batched,label) in enumerate(valid_dataloader):\n",
    "        batch_size=sample_batched.size(0)\n",
    "        sample_batched=sample_batched.to(device)\n",
    "        output=model(sample_batched)\n",
    "        loss=criterion(output,label.to(device))\n",
    "      #  loss=loss_func(output,label.float().to(device))\n",
    "        avg_vloss+=loss.item()\n",
    "        predicted = torch.max(output, 1)\n",
    "        prediction=predicted.indices.detach().cpu()\n",
    "        correct +=num_correct(prediction,label)\n",
    "        total_samples+=batch_size\n",
    "        \n",
    "        true_label=label.detach().cpu()\n",
    "        if first:\n",
    "            first=False\n",
    "            conf_mat=confusion_matrix( true_label,prediction,labels=[0,1,2])\n",
    "        else:\n",
    "            conf_mat+=confusion_matrix(true_label,prediction,labels=[0,1,2])\n",
    "    print(conf_mat)\n",
    "    avg_vloss=avg_vloss/len(valid_dataloader)\n",
    "    print(avg_vloss)\n",
    "    avg_vaccuracy=correct/(total_samples)\n",
    "    print(\"Accuracy: \", avg_vaccuracy)\n",
    "    \n",
    "   # data = \" %d,%d,%d,%d \\n\" % (avg_tloss,avg_taccuracy,avg_vloss,avg_vaccuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data1=dataload.Video_Frame_Data(Val_labels,base_path_v=Val_video,strict_num=26)\n",
    "\n",
    "valid_dataloader1 = DataLoader(valid_data1, batch_size=32\n",
    "                       , num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.eval()   \n",
    "    correct=0\n",
    "    total_samples=0\n",
    "    avg_vloss=0\n",
    "    first=True\n",
    "    model=model.float()\n",
    "    for i_batch, (sample_batched,_,label) in enumerate(valid_dataloader1):\n",
    "        batch_size=sample_batched.size(0)\n",
    "        sample_batched=sample_batched.to(device)\n",
    "        sample_batched=model.posencoding(model.stack_frame(sample_batched))\n",
    "        output=model(sample_batched)\n",
    "        loss=criterion(output,label.to(device))\n",
    "      #  loss=loss_func(output,label.float().to(device))\n",
    "        avg_vloss+=loss.item()\n",
    "        predicted = torch.max(output, 1)\n",
    "        prediction=predicted.indices.detach().cpu()\n",
    "        correct +=num_correct(prediction,label)\n",
    "        total_samples+=batch_size\n",
    "        \n",
    "        true_label=label.detach().cpu()\n",
    "        if first:\n",
    "            first=False\n",
    "            conf_mat=confusion_matrix( true_label,prediction,labels=[0,1,2])\n",
    "        else:\n",
    "            conf_mat+=confusion_matrix(true_label,prediction,labels=[0,1,2])\n",
    "    print(conf_mat)\n",
    "    avg_vloss=avg_vloss/len(valid_dataloader)\n",
    "    print(avg_vloss)\n",
    "    avg_vaccuracy=correct/(total_samples)\n",
    "    print(\"Accuracy: \", avg_vaccuracy)\n",
    "    \n",
    "   # data = \" %d,%d,%d,%d \\n\" % (avg_tloss,avg_taccuracy,avg_vloss,avg_vaccuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, (sample_batched,label) in enumerate(valid_dataloader):\n",
    "    debug=sample_batched\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        output=model(sample_batched)\n",
    "                                         \n",
    "        loss=criterion(output,label.to(device))\n",
    "      #  loss=loss_func(output,label.float().to(device))\n",
    "        avg_vloss+=loss.item()\n",
    "        predicted = torch.max(output, 1)\n",
    "        prediction=predicted.indices.detach().cpu()\n",
    "        correct +=num_correct(prediction,label)\n",
    "        total_samples+=batch_size\n",
    "        \n",
    "        true_label=label.detach().cpu()\n",
    "        if first:\n",
    "            first=False\n",
    "            conf_mat=confusion_matrix( true_label,prediction,labels=[0,1,2])\n",
    "        else:\n",
    "            conf_mat+=confusion_matrix(true_label,prediction,labels=[0,1,2])\n",
    "    print(conf_mat)\n",
    "    avg_vloss=avg_vloss/len(valid_dataloader)\n",
    "    print(avg_vloss)\n",
    "    avg_vaccuracy=correct/(total_samples)\n",
    "    print(\"Accuracy: \", avg_vaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "#f = open(\"result.txt\",'a')\n",
    "    start = time.time()\n",
    "    #Triaining\n",
    "    train_loss=[]\n",
    "    valid_accuracy=[]\n",
    "\n",
    "    model.train()\n",
    "    for epochs in range(0,1):\n",
    "        first=True\n",
    "        model.train()\n",
    "        correct=0\n",
    "        total_samples=0\n",
    "        avg_tloss=0\n",
    "        print(\"Training Epoch: \", epochs+1,\"\\n\")\n",
    "        for i_batch, (sample_batched,label) in enumerate(train_dataloader):\n",
    "\n",
    "            batch_size=sample_batched.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            sample_batched=sample_batched.to(device)\n",
    "            output=model(sample_batched)\n",
    "            loss=criterion(output,label.to(device))\n",
    "            #loss=loss_func(output,label.float().to(device))\n",
    "            loss.backward()\n",
    "            predicted = torch.max(output, 1)\n",
    "            prediction=predicted.indices.cpu()\n",
    "            correct +=num_correct(prediction,label)\n",
    "            total_samples+=batch_size\n",
    "            accuracy=correct/(total_samples)\n",
    "            optimizer.step()\n",
    "            label=label.cpu()\n",
    "            avg_tloss+=loss.item()\n",
    "            if first:\n",
    "                first=False\n",
    "                conf_mat=confusion_matrix( label,prediction,labels=[0,1,2])\n",
    "            else:\n",
    "                conf_mat+=confusion_matrix(label,prediction,labels=[0,1,2])\n",
    "            if i_batch%20==0:\n",
    "                #print(label)\n",
    "                print(\"Batch: \",i_batch+1,\"/\",len(train_dataloader))\n",
    "                print(\"Batch Recognition loss: \", loss.item())\n",
    "\n",
    "        print(conf_mat)\n",
    "        avg_tloss=avg_tloss/len(train_dataloader)\n",
    "        avg_taccuracy=correct/total_samples\n",
    "        print(\"Average_Loss: \",avg_tloss)\n",
    "        print(\"Average_Accuracy: \",avg_taccuracy)\n",
    "    end=time.time()\n",
    "    \n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
