{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from constant import AFFECTNETPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file,base_path,transform=None):\n",
    "        self.fields = ['subDirectory_filePath', 'expression','valence','arousal']\n",
    "        self._table = pd.read_csv(csv_file,usecols=self.fields)\n",
    "        \n",
    "        self._table=self._table[self._table['expression'] <8]\n",
    "\n",
    "        self._table=self._table.reset_index(drop=True)\n",
    "\n",
    "        self._base_path=base_path\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "        self.transform=transforms.Compose([\n",
    "                     transforms.Resize((64,64)),\n",
    "                     transforms.ToTensor(),   \n",
    "                     transforms.Normalize((0.5,0.5,0.5 ), (0.5, 0.5,0.5))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._table)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_name = os.path.join(self._base_path,self._table.subDirectory_filePath[idx])\n",
    "        img=Image.open(folder_name)\n",
    "        img=self.transform(img)\n",
    "        valence = torch.from_numpy(np.array(self._table.valence[idx]))\n",
    "        return (img,valence.float())\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Affect_Train=ImageDataset('training.csv',AFFECTNETPATH)\n",
    "Affect_Valid=ImageDataset('validation.csv',AFFECTNETPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def import_data(filename):\n",
    "    \"\"\"Import data in the second column of the supplied filename as floats.\"\"\"\n",
    "    with open(filename, 'r') as inf:\n",
    "        inf.readline()\n",
    "        return [float(row[2]) for row in csv.reader(inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287652"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Affect_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(Affect_Train, batch_size=256\n",
    "                       , num_workers=0,shuffle=True)\n",
    "\n",
    "valid_dataloader = DataLoader(Affect_Valid, batch_size=256\n",
    "                       , num_workers=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 is unfrozen\n",
      "bn1 is unfrozen\n",
      "relu is unfrozen\n",
      "maxpool is unfrozen\n",
      "layer1 is unfrozen\n",
      "layer2 is unfrozen\n",
      "layer3 is unfrozen\n",
      "layer4 is unfrozen\n",
      "avgpool is unfrozen\n",
      "fc is unfrozen\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "for name, child in resnet18.named_children():\n",
    "    if not name in []:\n",
    "        print(name + ' is unfrozen')\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        print(name + ' is frozen')\n",
    "        for param in child.parameters():\n",
    "               param.requires_grad = False\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F78A170DA50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=transforms.ToPILImage()(Affect_Train[26][0]*0.5+0.5)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import face_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "model=face_feature.Face_Feature(resnet18)\n",
    "\n",
    "\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#summary(model,(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7765]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Affect_Train[0][0].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch:  1 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51362886bdc04b9aa79593bd6130a231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.8641905188560486\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4740753173828125\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.4370391070842743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([164])) that is different to the input size (torch.Size([164, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ValidationLoss:  0.5525660626590252\n",
      "Training Epoch:  2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([160])) that is different to the input size (torch.Size([160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Face_Feature. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4044b7c9dd074b42bbe70500fed038ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.4402770400047302\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.45207110047340393\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.442383348941803\n",
      "\n",
      "ValidationLoss:  0.5613006167113781\n",
      "Training Epoch:  3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba7b0754b594a4d8bf0e2284da39ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.46387019753456116\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.43922555446624756\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.48780372738838196\n",
      "\n",
      "ValidationLoss:  0.5622653067111969\n",
      "Training Epoch:  4 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835644fab3d340339ed05731f8f650b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.4803837537765503\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4869186282157898\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.4827970564365387\n",
      "\n",
      "ValidationLoss:  0.5563184469938278\n",
      "Training Epoch:  5 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cacf84c42c8456ea5a727d1b8b92d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.45526057481765747\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4333847165107727\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.4704796373844147\n",
      "\n",
      "ValidationLoss:  0.5226161889731884\n",
      "Training Epoch:  6 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870592c231244d7d9e568d6de6df1177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.47010278701782227\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4393344521522522\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.4309175908565521\n",
      "\n",
      "ValidationLoss:  0.5195681899785995\n",
      "Training Epoch:  7 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1d9eb8ef0e4324a4699321a1825a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.4005727171897888\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.47701048851013184\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.45811256766319275\n",
      "\n",
      "ValidationLoss:  0.5553683266043663\n",
      "Training Epoch:  8 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fd11742437417e99ba0162561ae341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.45160117745399475\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4486909508705139\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.45064041018486023\n",
      "\n",
      "ValidationLoss:  0.5445472188293934\n",
      "Training Epoch:  9 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b7c76311954a2a8c768b568546a8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.46894726157188416\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.42819109559059143\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.46485036611557007\n",
      "\n",
      "ValidationLoss:  0.5264794621616602\n",
      "Training Epoch:  10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4f5c6d7151403299cda2ad8d18a2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.46664583683013916\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.45091456174850464\n",
      "Batch:  1001 / 1124\n",
      "MSE loss:  0.4493559002876282\n",
      "\n",
      "ValidationLoss:  0.5453268177807331\n",
      "Training Epoch:  11 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45aed39fc19428d805d50937b3d717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1 / 1124\n",
      "MSE loss:  0.44770950078964233\n",
      "Batch:  501 / 1124\n",
      "MSE loss:  0.4485887289047241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e9f667809853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6e08f99a9e2f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfolder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubDirectory_filePath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvalence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "num_epochs=50\n",
    "\n",
    "for epochs in (range(0,num_epochs)):\n",
    "    model.train()\n",
    "    print(\"Training Epoch: \", epochs+1,\"\\n\")\n",
    "   \n",
    "    for i_batch, (img,valence) in tqdm(enumerate(train_dataloader)):\n",
    "        batch_size=img.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        img=img.to(device)\n",
    "        val_output=model(img)\n",
    "        loss=loss_func(val_output,valence.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch%500==0:\n",
    "            print(\"Batch: \",i_batch+1,\"/\",len(train_dataloader))\n",
    "            print(\"MSE loss: \", loss.item())\n",
    "            train_loss.append(loss.item())\n",
    "    model.eval()\n",
    "    avg_loss=1e6\n",
    "    temp_loss=0\n",
    "    for i_batch, (img,valence) in enumerate(valid_dataloader):\n",
    "        \n",
    "        batch_size=img.size(0)\n",
    "\n",
    "        img=img.to(device)\n",
    "        val_output=model(img)\n",
    "        loss1=loss_func(val_output,valence.to(device))\n",
    "        temp_loss+=loss1.item()\n",
    "    avg_temp_loss=    temp_loss/len(valid_dataloader)\n",
    "    print(\"ValidationLoss: \",avg_temp_loss)\n",
    "    val_loss.append(avg_temp_loss)\n",
    "    if avg_temp_loss<avg_loss:\n",
    "        avg_loss=avg_temp_loss\n",
    "        torch.save(model,\"face_feature.h\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.resnet,\"pre_trained_resnet18_face.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.resnet.state_dict(), \"pretrained_state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
